# ===============
# best_ckpt=11, fold=0
# 2019-09-22 20:21:17,224 - INFO - Mean train loss: 0.00841
# 2019-09-22 20:22:24,301 - INFO - Mean valid loss: 0.00855
# 2019-09-22 20:23:32,791 - INFO - Mean EMA valid loss: 0.00803
# 2019-09-23 06:08:22,377 - INFO - dice=0.9667818835644745 on 800
# 2019-09-23 06:09:54,324 - INFO - dice=0.9899488094674251 on 800
# 2019-09-23 06:11:25,569 - INFO - dice=0.8673755849027167 on 800
# 2019-09-23 06:12:25,661 - INFO - dice=0.9847439999198341 on 400
# 2019-09-23 13:12:00,649 - INFO - dice=0.9691685184093431 on 0.17
# 2019-09-23 13:40:14,458 - INFO - dice=0.99034658194157 on 0.08
# 2019-09-23 14:08:25,024 - INFO - dice=0.8754584861686093 on 0.65
# 2019-09-23 14:36:54,637 - INFO - dice=0.9859557605689044 on 0.42
# best_ckpt=17, fold=1
# 2019-09-23 01:15:26,062 - INFO - Mean train loss: 0.00707
# 2019-09-23 01:16:32,374 - INFO - Mean valid loss: 0.00871
# 2019-09-23 01:17:39,554 - INFO - Mean EMA valid loss: 0.00833
# 2019-09-25 01:20:59,390 - INFO - dice=0.9700806242900795 on 200
# 2019-09-25 01:21:14,959 - INFO - dice=0.9714453285451523 on 400
# 2019-09-25 01:21:30,244 - INFO - dice=0.9722684458038867 on 600
# 2019-09-25 01:21:45,659 - INFO - dice=0.9712354968160436 on 800
# 2019-09-25 01:22:00,913 - INFO - dice=0.9700598954901138 on 1000
# 2019-09-25 01:22:16,236 - INFO - dice=0.9695154969651276 on 1200
# 2019-09-25 01:22:31,541 - INFO - dice=0.9677711852128894 on 1400
# 2019-09-25 01:22:46,815 - INFO - dice=0.9660053552612671 on 1600
# 2019-09-25 01:23:02,438 - INFO - dice=0.9642925368161004 on 1800
# 2019-09-25 01:23:30,519 - INFO - dice=0.9892882883169681 on 200
# 2019-09-25 01:23:45,795 - INFO - dice=0.9892882883169681 on 400
# 2019-09-25 01:24:01,102 - INFO - dice=0.9887316338671652 on 600
# 2019-09-25 01:24:16,468 - INFO - dice=0.988216861861542 on 800
# 2019-09-25 01:24:31,884 - INFO - dice=0.9881884815958949 on 1000
# 2019-09-25 01:24:47,216 - INFO - dice=0.9885575152640024 on 1200
# 2019-09-25 01:25:02,590 - INFO - dice=0.9881949449233345 on 1400
# 2019-09-25 01:25:17,906 - INFO - dice=0.9874509947556467 on 1600
# 2019-09-25 01:25:33,131 - INFO - dice=0.9866168582807119 on 1800
# 2019-09-25 01:26:00,903 - INFO - dice=0.8627605396534969 on 200
# 2019-09-25 01:26:15,992 - INFO - dice=0.864242476854753 on 400
# 2019-09-25 01:26:31,087 - INFO - dice=0.8659892474212854 on 600
# 2019-09-25 01:26:46,156 - INFO - dice=0.867231172767689 on 800
# 2019-09-25 01:27:01,301 - INFO - dice=0.8678165780557164 on 1000
# 2019-09-25 01:27:16,477 - INFO - dice=0.8685196727378591 on 1200
# 2019-09-25 01:27:31,566 - INFO - dice=0.8677339942798094 on 1400
# 2019-09-25 01:27:46,633 - INFO - dice=0.8672832574639495 on 1600
# 2019-09-25 01:28:01,720 - INFO - dice=0.8658555847606202 on 1800
# 2019-09-25 01:28:29,486 - INFO - dice=0.9804667007262526 on 200
# 2019-09-25 01:28:44,672 - INFO - dice=0.980864315040368 on 400
# 2019-09-25 01:28:59,805 - INFO - dice=0.9816595436685985 on 600
# 2019-09-25 01:29:14,974 - INFO - dice=0.9816595436685985 on 800
# 2019-09-25 01:29:30,058 - INFO - dice=0.9816595436685985 on 1000
# 2019-09-25 01:29:45,227 - INFO - dice=0.9816595436685985 on 1200
# 2019-09-25 01:30:00,312 - INFO - dice=0.9816595436685985 on 1400
# 2019-09-25 01:30:15,408 - INFO - dice=0.9816595436685985 on 1600
# 2019-09-25 01:30:30,370 - INFO - dice=0.9816595436685985 on 1800
# 2019-09-25 01:30:30,371 - INFO - holdout dice=0.9496061308815078
# best_ckpt=13, fold=2
# 2019-09-22 21:40:58,876 - INFO - Mean train loss: 0.00805
# 2019-09-22 21:42:04,469 - INFO - Mean valid loss: 0.00859
# 2019-09-22 21:43:08,734 - INFO - Mean EMA valid loss: 0.008121
# 2019-09-25 01:47:33,902 - INFO - dice=0.9628720052950338 on 200
# 2019-09-25 01:47:49,006 - INFO - dice=0.9647150513616962 on 400
# 2019-09-25 01:48:04,118 - INFO - dice=0.9653047705316691 on 600
# 2019-09-25 01:48:19,216 - INFO - dice=0.9658504362495761 on 800
# 2019-09-25 01:48:34,447 - INFO - dice=0.9646775166927418 on 1000
# 2019-09-25 01:48:49,567 - INFO - dice=0.9642448624332545 on 1200
# 2019-09-25 01:49:04,686 - INFO - dice=0.9631046275452507 on 1400
# 2019-09-25 01:49:19,788 - INFO - dice=0.9601982646864428 on 1600
# 2019-09-25 01:49:34,889 - INFO - dice=0.9588713646159983 on 1800
# 2019-09-25 01:50:02,599 - INFO - dice=0.9881331379988421 on 200
# 2019-09-25 01:50:17,720 - INFO - dice=0.9888169121692728 on 400
# 2019-09-25 01:50:32,873 - INFO - dice=0.9894448090437722 on 600
# 2019-09-25 01:50:48,132 - INFO - dice=0.9894448090437722 on 800
# 2019-09-25 01:51:03,231 - INFO - dice=0.989842581517917 on 1000
# 2019-09-25 01:51:18,468 - INFO - dice=0.989128284167969 on 1200
# 2019-09-25 01:51:33,566 - INFO - dice=0.989128284167969 on 1400
# 2019-09-25 01:51:48,689 - INFO - dice=0.989128284167969 on 1600
# 2019-09-25 01:52:03,791 - INFO - dice=0.9885435094555175 on 1800
# 2019-09-25 01:52:31,278 - INFO - dice=0.8627188574655552 on 200
# 2019-09-25 01:52:46,325 - INFO - dice=0.8657727241493364 on 400
# 2019-09-25 01:53:01,313 - INFO - dice=0.8668609770636675 on 600
# 2019-09-25 01:53:16,298 - INFO - dice=0.86705901440224 on 800
# 2019-09-25 01:53:31,283 - INFO - dice=0.8657003235625592 on 1000
# 2019-09-25 01:53:46,288 - INFO - dice=0.8659628766023796 on 1200
# 2019-09-25 01:54:01,391 - INFO - dice=0.8639783462107511 on 1400
# 2019-09-25 01:54:16,381 - INFO - dice=0.8622840091191837 on 1600
# 2019-09-25 01:54:31,359 - INFO - dice=0.8618813728824312 on 1800
# 2019-09-25 01:54:58,865 - INFO - dice=0.9839436115495497 on 200
# 2019-09-25 01:55:14,137 - INFO - dice=0.9838371364064188 on 400
# 2019-09-25 01:55:29,261 - INFO - dice=0.9838371364064188 on 600
# 2019-09-25 01:55:44,371 - INFO - dice=0.9842349088805635 on 800
# 2019-09-25 01:55:59,630 - INFO - dice=0.9842349088805635 on 1000
# 2019-09-25 01:56:14,736 - INFO - dice=0.9842349088805635 on 1200
# 2019-09-25 01:56:29,839 - INFO - dice=0.9842349088805635 on 1400
# 2019-09-25 01:56:45,031 - INFO - dice=0.9842349088805635 on 1600
# 2019-09-25 01:57:00,108 - INFO - dice=0.9842349088805635 on 1800
# 2019-09-25 01:57:00,109 - INFO - holdout dice=0.9483827889586276
# best_ckpt=13, fold=3
# 2019-09-22 21:43:32,186 - INFO - Mean train loss: 0.00722
# 2019-09-22 21:44:33,931 - INFO - Mean valid loss: 0.00869
# 2019-09-22 21:45:36,636 - INFO - Mean EMA valid loss: 0.00859
# 2019-09-25 03:24:10,537 - INFO - dice=0.9646712471301488 on 200
# 2019-09-25 03:24:26,010 - INFO - dice=0.9658650394102921 on 400
# 2019-09-25 03:24:41,403 - INFO - dice=0.9664701675293965 on 600
# 2019-09-25 03:24:56,785 - INFO - dice=0.9656122500156997 on 800
# 2019-09-25 03:25:12,227 - INFO - dice=0.9637170715483983 on 1000
# 2019-09-25 03:25:27,589 - INFO - dice=0.9645883601567579 on 1200
# 2019-09-25 03:25:42,981 - INFO - dice=0.9618711391664457 on 1400
# 2019-09-25 03:25:58,284 - INFO - dice=0.9589678631363021 on 1600
# 2019-09-25 03:26:13,565 - INFO - dice=0.9561898113794156 on 1800
# 2019-09-25 03:26:42,548 - INFO - dice=0.9916672196450285 on 200
# 2019-09-25 03:26:57,887 - INFO - dice=0.9916672196450285 on 400
# 2019-09-25 03:27:13,192 - INFO - dice=0.9918062269420166 on 600
# 2019-09-25 03:27:28,501 - INFO - dice=0.9918760247203339 on 800
# 2019-09-25 03:27:44,033 - INFO - dice=0.9922739554803817 on 1000
# 2019-09-25 03:27:59,511 - INFO - dice=0.9918530133721436 on 1200
# 2019-09-25 03:28:14,879 - INFO - dice=0.9918530133721436 on 1400
# 2019-09-25 03:28:30,329 - INFO - dice=0.9918530133721436 on 1600
# 2019-09-25 03:28:45,639 - INFO - dice=0.9915880642518824 on 1800
# 2019-09-25 03:29:14,240 - INFO - dice=0.8721706689927418 on 200
# 2019-09-25 03:29:29,460 - INFO - dice=0.8738386435718051 on 400
# 2019-09-25 03:29:44,685 - INFO - dice=0.8753709650057766 on 600
# 2019-09-25 03:29:59,909 - INFO - dice=0.8751205833950145 on 800
# 2019-09-25 03:30:15,147 - INFO - dice=0.8741400516817326 on 1000
# 2019-09-25 03:30:30,442 - INFO - dice=0.8727935829832424 on 1200
# 2019-09-25 03:30:45,717 - INFO - dice=0.8714400432911835 on 1400
# 2019-09-25 03:31:00,937 - INFO - dice=0.8717518460621664 on 1600
# 2019-09-25 03:31:16,150 - INFO - dice=0.869737990556141 on 1800
# 2019-09-25 03:31:45,106 - INFO - dice=0.9827229036410915 on 200
# 2019-09-25 03:32:00,615 - INFO - dice=0.9827229036410915 on 400
# 2019-09-25 03:32:15,917 - INFO - dice=0.9826946148505062 on 600
# 2019-09-25 03:32:31,183 - INFO - dice=0.9830819768200014 on 800
# 2019-09-25 03:32:46,630 - INFO - dice=0.9830819768200014 on 1000
# 2019-09-25 03:33:02,039 - INFO - dice=0.9830819768200014 on 1200
# 2019-09-25 03:33:17,478 - INFO - dice=0.9830819768200014 on 1400
# 2019-09-25 03:33:32,928 - INFO - dice=0.9834799075800491 on 1600
# 2019-09-25 03:33:48,240 - INFO - dice=0.9834799075800491 on 1800
# 2019-09-25 03:33:48,241 - INFO - holdout dice=0.9502489434418719
# best_ckpt=9, fold=4
# 2019-09-23 02:31:39,970 - INFO - Mean train loss: 0.00865
# 2019-09-23 02:32:47,933 - INFO - Mean valid loss: 0.0085
# 2019-09-23 02:33:57,067 - INFO - Mean EMA valid loss: 0.00809
# ===============
import os
import gc
import copy
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
#import segmentation_models_pytorch as smp
from apex import amp
from contextlib import contextmanager
from albumentations import *
import torch
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import CosineAnnealingLR

import sys
sys.path.append("../severstal-src/")
from util import seed_torch, search_threshold
from losses import FocalLovaszLoss
from datasets import SeverDataset, MaskProbSampler
from logger import setup_logger, LOGGER
from trainer import train_one_epoch, validate
from scheduler import GradualWarmupScheduler
sys.path.append("../")
import segmentation_models_pytorch as smp
from sync_batchnorm import convert_model


# ===============
# Constants
# ===============
IMG_DIR = "../input/train_images/"
LOGGER_PATH = "log.txt"
FOLD_PATH = "../input/severstal_folds01.csv"
ID_COLUMNS = "ImageId"
N_CLASSES = 4


# ===============
# Settings
# ===============
SEED = np.random.randint(100000)
device = "cuda"
IMG_SIZE = (1600, 256)
CLR_CYCLE = 3
BATCH_SIZE = 32
EPOCHS = 119
FOLD_ID = 1
EXP_ID = "exp57_unet_resnet"
CLASSIFICATION = True
EMA = True
EMA_START = 6
base_ckpt = 15
base_model = None
base_model_ema = None
base_model = "models/{}_fold{}_latest.pth".format(EXP_ID, FOLD_ID)
base_model_ema = "models/{}_fold{}_latest_ema.pth".format(EXP_ID, FOLD_ID)

setup_logger(out_file=LOGGER_PATH)
seed_torch(SEED)
LOGGER.info("seed={}".format(SEED))


@contextmanager
def timer(name):
    t0 = time.time()
    yield
    LOGGER.info('[{}] done in {} s'.format(name, round(time.time() - t0, 2)))


def main(seed):
    with timer('load data'):
        df = pd.read_csv(FOLD_PATH)
        y1 = (df.EncodedPixels_1 != "-1").astype("float32").values.reshape(-1, 1)
        y2 = (df.EncodedPixels_2 != "-1").astype("float32").values.reshape(-1, 1)
        y3 = (df.EncodedPixels_3 != "-1").astype("float32").values.reshape(-1, 1)
        y4 = (df.EncodedPixels_4 != "-1").astype("float32").values.reshape(-1, 1)
        y = np.concatenate([y1, y2, y3, y4], axis=1)

    with timer('preprocessing'):
        train_df, val_df = df[df.fold_id != FOLD_ID], df[df.fold_id == FOLD_ID]
        y_train, y_val = y[df.fold_id != FOLD_ID], y[df.fold_id == FOLD_ID]

        train_augmentation = Compose([
            Flip(p=0.5),
            OneOf([
                GridDistortion(p=0.5),
                OpticalDistortion(p=0.5, distort_limit=2, shift_limit=0.5)
            ], p=0.5),
            OneOf([
                RandomGamma(gamma_limit=(100,140), p=0.5),
                RandomBrightnessContrast(p=0.5),
                RandomBrightness(p=0.5),
                RandomContrast(p=0.5)
            ], p=0.5),
            OneOf([
                GaussNoise(p=0.5),
                Cutout(num_holes=10, max_h_size=10, max_w_size=20, p=0.5)
            ], p=0.5),
            ShiftScaleRotate(rotate_limit=20, p=0.5),
        ])
        val_augmentation = None

        train_dataset = SeverDataset(train_df, IMG_DIR, IMG_SIZE, N_CLASSES, id_colname=ID_COLUMNS,
                                    transforms=train_augmentation, crop_rate=1.0, class_y=y_train)
        val_dataset = SeverDataset(val_df, IMG_DIR, IMG_SIZE, N_CLASSES, id_colname=ID_COLUMNS,
                                  transforms=val_augmentation)
        train_sampler = MaskProbSampler(train_df, demand_non_empty_proba=0.6)
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=8, pin_memory=True)
        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)

        del train_df, val_df, df, train_dataset, val_dataset
        gc.collect()

    with timer('create model'):
        model = smp.Unet('resnet34', encoder_weights="imagenet", classes=N_CLASSES, encoder_se_module=True,
                         decoder_semodule=True, h_columns=False, skip=True, act="swish", freeze_bn=True,
                         classification=CLASSIFICATION, attention_type="cbam", center=True)
        model = convert_model(model)
        if base_model is not None:
            model.load_state_dict(torch.load(base_model))
        model.to(device)

        criterion = torch.nn.BCEWithLogitsLoss()
        optimizer = torch.optim.Adam([
            {'params': model.decoder.parameters(), 'lr': 3e-3},
            {'params': model.encoder.parameters(), 'lr': 3e-4}
        ], eps=1e-4)
        if base_model is None:
            scheduler_cosine = CosineAnnealingLR(optimizer, T_max=CLR_CYCLE, eta_min=3e-5)
            scheduler = GradualWarmupScheduler(optimizer, multiplier=1.1, total_epoch=CLR_CYCLE*2, after_scheduler=scheduler_cosine)
        else:
            scheduler = CosineAnnealingLR(optimizer, T_max=CLR_CYCLE, eta_min=3e-5)


        model, optimizer = amp.initialize(model, optimizer, opt_level="O1", verbosity=0)

        if EMA:
            ema_model = copy.deepcopy(model)
            if base_model_ema is not None:
                ema_model.load_state_dict(torch.load(base_model_ema))
            ema_model.to(device)
        else:
            ema_model = None
        model = torch.nn.DataParallel(model)
        ema_model = torch.nn.DataParallel(ema_model)

    with timer('train'):
        train_losses = []
        valid_losses = []

        best_model_loss = 999
        best_model_ema_loss = 999
        best_model_ep = 0
        ema_decay = 0
        checkpoint = base_ckpt+1

        for epoch in range(90, EPOCHS + 1):
            seed = seed + epoch
            seed_torch(seed)

            if epoch >= EMA_START:
                ema_decay = 0.99

            LOGGER.info("Starting {} epoch...".format(epoch))
            tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, cutmix_prob=0.0,
                                      classification=CLASSIFICATION, ema_model=ema_model, ema_decay=ema_decay)
            train_losses.append(tr_loss)
            LOGGER.info('Mean train loss: {}'.format(round(tr_loss, 5)))

            valid_loss = validate(model, val_loader, criterion, device, classification=CLASSIFICATION)
            valid_losses.append(valid_loss)
            LOGGER.info('Mean valid loss: {}'.format(round(valid_loss, 5)))

            if EMA and epoch >= EMA_START:
                ema_valid_loss = validate(ema_model, val_loader, criterion, device, classification=CLASSIFICATION)
                LOGGER.info('Mean EMA valid loss: {}'.format(round(ema_valid_loss, 5)))

                if ema_valid_loss < best_model_ema_loss:
                    torch.save(ema_model.module.state_dict(),
                               'models/{}_fold{}_ckpt{}_ema.pth'.format(EXP_ID, FOLD_ID, checkpoint))
                    best_model_ema_loss = ema_valid_loss

            scheduler.step()

            if valid_loss < best_model_loss:
                torch.save(model.module.state_dict(), 'models/{}_fold{}_ckpt{}.pth'.format(EXP_ID, FOLD_ID, checkpoint))
                best_model_loss = valid_loss
                best_model_ep = epoch
                #np.save("val_pred.npy", val_pred)

            if epoch % (CLR_CYCLE * 2) == CLR_CYCLE * 2 - 1:
                torch.save(model.module.state_dict(), 'models/{}_fold{}_latest.pth'.format(EXP_ID, FOLD_ID))
                LOGGER.info('Best valid loss: {} on epoch={}'.format(round(best_model_loss, 5), best_model_ep))
                if EMA:
                    torch.save(ema_model.module.state_dict(), 'models/{}_fold{}_latest_ema.pth'.format(EXP_ID, FOLD_ID))
                    LOGGER.info('Best ema valid loss: {}'.format(round(best_model_ema_loss, 5)))
                checkpoint += 1
                best_model_loss = 999

            #del val_pred
            gc.collect()

    LOGGER.info('Best valid loss: {} on epoch={}'.format(round(best_model_loss, 5), best_model_ep))

    xs = list(range(1, len(train_losses) + 1))
    plt.plot(xs, train_losses, label='Train loss')
    plt.plot(xs, valid_losses, label='Val loss')
    plt.legend()
    plt.xticks(xs)
    plt.xlabel('Epochs')
    plt.savefig("loss.png")


if __name__ == '__main__':
    main(SEED)
